{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7ac2ba",
   "metadata": {},
   "source": [
    "## MNIST CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch libraries \n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# other data libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11419d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load the data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# load the data into a DataLoader, turn into batches and shuffle\n",
    "loaders = {\n",
    "    \"train\": DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
    "    \"test\": DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1704aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model architecture\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "\n",
    "        # define input, hidden, output\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)  # 1 channel in, 10 out\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)  # 10 channels in, 20 out\n",
    "        self.conv2_dropout = nn.Dropout2d()  # dropout layer is a regualarization layer (randomly deactivates certain network nodes)\n",
    "        self.fcl1 = nn.Linear(320, 50)\n",
    "        self.fcl2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_dropout(self.conv2(x)), 2))\n",
    "\n",
    "        # flatten data\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fcl1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fcl2(x)\n",
    "\n",
    "        return F.softmax(x)\n",
    "\n",
    "    def train_model(self, training_data, epochs, optimizer, loss_fuc, model):\n",
    "        model.train()\n",
    "\n",
    "        for batch_i, (data, target) in enumerate(training_data):\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            loss = loss_fuc(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        if batch_i % 20 == 0:\n",
    "            print(f\"Train Epoch: {epochs} [{batch_i * len(data)}/{len(training_data)} ({100. * batch_i / len(training_data):.0f}%)]\\t{loss.item():.6f}\")\n",
    "\n",
    "\n",
    "    def test_model(self, model, testing_data, optimizer, loss_fuc):\n",
    "        model.eval()\n",
    "\n",
    "        test_loss = correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in testing_data:\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                test_loss += loss_fuc(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(testing_data)\n",
    "        print(f\"\\nTest Set: Average Loss: {test_loss:.4f}, Accuracy: {correct}/{len(testing_data)} ({100. * correct / len(testing_data):.0f}%\\n)\")\n",
    "        \n",
    "\n",
    "\n",
    "    def predict_digit(self, model, img_tensor):\n",
    "        output = model(img_tensor)\n",
    "        prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "        print(f\"Prediction: {prediction}\")\n",
    "\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def save_model(self, model, path):\n",
    "        torch.save(model, path)\n",
    "\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4e8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model, optimizer model, loss function\n",
    "model = MNIST_CNN().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fuc = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0677cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model, save it\n",
    "epochs = 500\n",
    "model.train_model(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
